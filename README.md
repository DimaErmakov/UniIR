# UniIR
### This repo is under construction. Please stay tuned.

[**🌐 Homepage**](https://tiger-ai-lab.github.io/UniIR/) | [**🤗 Dataset**](https://huggingface.co/datasets/TIGER-Lab/M-BEIR) | [**📖 arXiv**](https://arxiv.org/pdf/2311.17136.pdf) | [**GitHub**](https://github.com/TIGER-AI-Lab/UniIR)

This repo contains the codebase for the paper "[UniIR: Training and Benchmarking Universal Multimodal
Information Retrievers](https://arxiv.org/pdf/2311.17136.pdf)"

# UniIR Models
Universal multimodal Information Retrieval (UniIR)
## Training
### Environment Setup
### Scripts
## Evaluation
### Environment Setup
### Scripts
## Model Zoo

# M-BEIR
Multimodal BEnchmark for Instructed Retrieval (M-BEIR)

## M-BEIR Dataset Structure

```
mbeir_data
├── mbeir_train.jsonl
├── mbeir_val.jsonl
├── mbeir_test.jsonl
├── mbeir_instructions.tsv
├── mbeir_images
│   ├── oven_images
│   ├── infoseek_images
│   ├── edis_images
│   ├── webqa_images
│   ├── mscoco_images
...
```
###  UniIR Instructions

###  M-BEIR format

###  M-BEIR Statistics

###  M-BEIR Downloading


## Contact
- Cong Wei: c58wei@uwaterloo.ca
- Yang Chen: yangc@gatech.edu
- Alan Ritter: alan.ritter@cc.gatech.edu
- Wenhu Chen: wenhuchen@uwaterloo.ca

## Citation

**BibTeX:**
```bibtex
@article{wei2023uniir,
  title={UniIR: Training and Benchmarking Universal Multimodal Information Retrievers},
  author={Wei, Cong and Chen, Yang and Chen, Haonan and Hu, Hexiang and Zhang, Ge and Fu, Jie and Ritter, Alan and Chen, Wenhu},
  journal={arXiv preprint arXiv:2311.17136},
  year={2023}
}
```
